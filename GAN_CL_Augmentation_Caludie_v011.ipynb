{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67d159b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Malli\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Malli\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data, Dataset, DataLoader, Batch\n",
    "from torch_geometric.nn import GCNConv, SAGEConv, GATConv, global_mean_pool, global_add_pool\n",
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "import warnings\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "from torch_scatter import scatter_add, scatter_softmax, scatter_mean, scatter_max\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def get_atom_features(atom):\n",
    "    \"\"\"More comprehensive atom features as per attachment\"\"\"\n",
    "    features = []\n",
    "    features.append(atom.GetAtomicNum())\n",
    "    features.append(atom.GetDegree())\n",
    "    features.append(atom.GetFormalCharge())\n",
    "    features.append(int(atom.GetHybridization()))\n",
    "    features.append(int(atom.GetIsAromatic()))\n",
    "    features.append(int(atom.IsInRing()))\n",
    "    return features\n",
    "\n",
    "def get_bond_features(bond):\n",
    "    \"\"\"More comprehensive bond features as per attachment\"\"\"\n",
    "    features = []\n",
    "    bond_type = bond.GetBondType()\n",
    "    bond_dict = {\n",
    "        Chem.rdchem.BondType.SINGLE: 0,\n",
    "        Chem.rdchem.BondType.DOUBLE: 1,\n",
    "        Chem.rdchem.BondType.TRIPLE: 2,\n",
    "        Chem.rdchem.BondType.AROMATIC: 3\n",
    "    }\n",
    "    features.append(bond_dict.get(bond_type, -1))\n",
    "    features.append(int(bond.GetIsConjugated()))\n",
    "    features.append(int(bond.IsInRing()))\n",
    "    features.append(int(bond.GetStereo()))\n",
    "    return features\n",
    "\n",
    "class MolecularGraphDataset(Dataset):\n",
    "    def __init__(self, smiles_list):\n",
    "        super().__init__()\n",
    "        self.smiles_list = smiles_list\n",
    "        self.graphs = []\n",
    "        self._process_smiles()\n",
    "        \n",
    "    def _process_smiles(self):\n",
    "        for smiles in self.smiles_list:\n",
    "            mol = Chem.MolFromSmiles(smiles)\n",
    "            if mol is None:\n",
    "                continue\n",
    "            \n",
    "            # Kekulize the molecule as recommended\n",
    "            Chem.Kekulize(mol, clearAromaticFlags=True)\n",
    "            \n",
    "            # Get node features\n",
    "            atom_features_list = []\n",
    "            for atom in mol.GetAtoms():\n",
    "                atom_features_list.append(get_atom_features(atom))\n",
    "            x = torch.tensor(atom_features_list, dtype=torch.float)\n",
    "            \n",
    "            # Get edge features and indices\n",
    "            edge_indices = []\n",
    "            edge_features = []\n",
    "            for bond in mol.GetBonds():\n",
    "                i = bond.GetBeginAtomIdx()\n",
    "                j = bond.GetEndAtomIdx()\n",
    "                \n",
    "                features = get_bond_features(bond)\n",
    "                \n",
    "                # Add both directions for undirected graph\n",
    "                edge_indices.extend([[i, j], [j, i]])\n",
    "                edge_features.extend([features, features])\n",
    "            \n",
    "            if len(edge_indices) == 0:\n",
    "                continue  # Skip molecules without bonds\n",
    "            \n",
    "            edge_index = torch.tensor(edge_indices, dtype=torch.long).t().contiguous()\n",
    "            edge_attr = torch.tensor(edge_features, dtype=torch.float)\n",
    "            \n",
    "            data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr)\n",
    "            self.graphs.append(data)\n",
    "    \n",
    "    def len(self):  # Changed from __len__ to len\n",
    "        return len(self.graphs)\n",
    "    \n",
    "    def get(self, idx):  # Changed from __getitem__ to get\n",
    "        return self.graphs[idx]\n",
    "\n",
    "class MolecularGraphGenerator(nn.Module):\n",
    "    def __init__(self, num_atom_features, num_bond_features, hidden_dim=128, latent_dim=16):\n",
    "        super().__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # Initial node feature encoder\n",
    "        self.node_encoder = nn.Sequential(\n",
    "            nn.Linear(num_atom_features + latent_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim)\n",
    "        )\n",
    "        \n",
    "        # Multi-scale graph convolutions\n",
    "        self.graph_conv1 = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.graph_conv2 = SAGEConv(hidden_dim, hidden_dim)\n",
    "        self.graph_conv3 = GATConv(hidden_dim, hidden_dim)\n",
    "        \n",
    "        # Edge attention and features\n",
    "        self.edge_attention = nn.Sequential(\n",
    "            nn.Linear(2 * hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        self.edge_features = nn.Sequential(\n",
    "            nn.Linear(2 * hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, num_bond_features),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "         # Node decoder\n",
    "        self.node_decoder = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, num_atom_features)\n",
    "        )\n",
    "        \n",
    "        # Augmentation parameters\n",
    "        self.node_drop_rate = 0.1\n",
    "        self.edge_drop_rate = 0.1\n",
    "        self.subgraph_size_range = (0.5, 0.9)\n",
    "        \n",
    "    def grow_subgraph(self, edge_index, num_nodes, seed_node, target_size):\n",
    "            \"\"\"\n",
    "            Grows a subgraph from a seed node using BFS until reaching target size\n",
    "            \"\"\"\n",
    "            device = edge_index.device\n",
    "            subgraph_nodes = {seed_node}\n",
    "            frontier = {seed_node}\n",
    "\n",
    "            edge_index_list = edge_index.t().cpu().numpy().tolist()\n",
    "            edges = {(src, dst) for src, dst in edge_index_list}\n",
    "\n",
    "            while len(subgraph_nodes) < target_size and frontier:\n",
    "                new_frontier = set()\n",
    "                for node in frontier:\n",
    "                    # Find neighbors\n",
    "                    neighbors = {dst for src, dst in edges if src == node}\n",
    "                    neighbors.update({src for src, dst in edges if dst == node})\n",
    "\n",
    "                    # Add unvisited neighbors\n",
    "                    new_nodes = neighbors - subgraph_nodes\n",
    "                    if len(subgraph_nodes) + len(new_nodes) > target_size:\n",
    "                        # Randomly select nodes to add\n",
    "                        remaining = target_size - len(subgraph_nodes)\n",
    "                        new_nodes = set(random.sample(list(new_nodes), remaining))\n",
    "\n",
    "                    subgraph_nodes.update(new_nodes)\n",
    "                    new_frontier.update(new_nodes)\n",
    "\n",
    "                    if len(subgraph_nodes) >= target_size:\n",
    "                        break\n",
    "\n",
    "                frontier = new_frontier\n",
    "\n",
    "            return torch.tensor(list(subgraph_nodes), device=device)      \n",
    "        \n",
    "    def pad_to_nearest_power_of_two(self, x, edge_index, edge_attr):\n",
    "        \"\"\"\n",
    "        Pad node features and edges to nearest power of 2 for consistent sizes\n",
    "        \"\"\"\n",
    "        current_nodes = x.size(0)\n",
    "        # Find next power of 2\n",
    "        next_power = 2 ** (current_nodes - 1).bit_length()\n",
    "        pad_size = next_power - current_nodes\n",
    "\n",
    "        if pad_size > 0:\n",
    "            # Pad node features\n",
    "            x_pad = torch.zeros(pad_size, x.size(1), device=x.device)\n",
    "            x = torch.cat([x, x_pad], dim=0)\n",
    "\n",
    "            # Update edge indices\n",
    "            if edge_index.numel() > 0:\n",
    "                dummy_edges = torch.zeros(2, pad_size, device=edge_index.device, dtype=edge_index.dtype)\n",
    "                dummy_edges[0] = torch.arange(current_nodes, current_nodes + pad_size, device=edge_index.device)\n",
    "                dummy_edges[1] = torch.arange(current_nodes, current_nodes + pad_size, device=edge_index.device)\n",
    "                edge_index = torch.cat([edge_index, dummy_edges], dim=1)\n",
    "\n",
    "                # Pad edge attributes\n",
    "                edge_attr_pad = torch.zeros(pad_size, edge_attr.size(1), device=edge_attr.device)\n",
    "                edge_attr = torch.cat([edge_attr, edge_attr_pad], dim=0)\n",
    "\n",
    "        return x, edge_index, edge_attr        \n",
    "        \n",
    "    def node_augmentation(self, x, batch):\n",
    "        \"\"\"Node feature augmentation with tensor handling\"\"\"\n",
    "        device = x.device\n",
    "        batch_size = int(batch.max().item() + 1)\n",
    "        node_mask = torch.ones(x.size(0), device=device)\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            batch_mask = (batch == i)\n",
    "            batch_nodes = batch_mask.sum()\n",
    "            \n",
    "            # Randomly drop nodes while keeping minimum structure\n",
    "            if batch_nodes > 4:\n",
    "                drop_mask = (torch.rand(batch_nodes.item(), device=device) > self.node_drop_rate)\n",
    "                node_mask[batch_mask] *= drop_mask\n",
    "        \n",
    "        # Feature masking and perturbation\n",
    "        feature_mask = (torch.rand_like(x) > 0.1)\n",
    "        perturbation = torch.randn_like(x) * 0.1\n",
    "        \n",
    "        augmented_x = x * node_mask.unsqueeze(1) * feature_mask + perturbation\n",
    "        return augmented_x, node_mask\n",
    "    \n",
    "    def edge_augmentation(self, edge_index, edge_attr, node_mask, batch):\n",
    "        \"\"\"Edge augmentation with proper tensor handling\"\"\"\n",
    "        device = edge_index.device\n",
    "        \n",
    "        # Apply node mask to edges\n",
    "        edge_mask = node_mask[edge_index[0]] * node_mask[edge_index[1]]\n",
    "        \n",
    "        # Random edge dropping\n",
    "        random_drop = (torch.rand(edge_index.size(1), device=device) > self.edge_drop_rate)\n",
    "        edge_mask = edge_mask * random_drop\n",
    "        \n",
    "        # Edge feature perturbation\n",
    "        edge_perturbation = torch.randn_like(edge_attr) * 0.1\n",
    "        augmented_edge_attr = edge_attr + edge_perturbation\n",
    "        \n",
    "        # Filter edges and attributes\n",
    "        kept_edges = edge_mask.bool()\n",
    "        augmented_edge_index = edge_index[:, kept_edges]\n",
    "        augmented_edge_attr = augmented_edge_attr[kept_edges]\n",
    "        \n",
    "        return augmented_edge_index, augmented_edge_attr\n",
    "    \n",
    "    def subgraph_augmentation(self, x, edge_index, edge_attr, batch):\n",
    "        \"\"\"Subgraph augmentation with proper tensor handling\"\"\"\n",
    "        device = x.device\n",
    "        batch_size = int(batch.max().item() + 1)\n",
    "        subgraph_masks = []\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            batch_mask = (batch == i)\n",
    "            num_nodes = batch_mask.sum().item()\n",
    "\n",
    "            # Get edges for this batch\n",
    "            edge_mask = (batch[edge_index[0]] == i) & (batch[edge_index[1]] == i)\n",
    "            batch_edges = edge_index[:, edge_mask]\n",
    "\n",
    "            # Remap node indices to local indexing\n",
    "            node_idx_map = torch.zeros(batch.size(0), dtype=torch.long, device=device)\n",
    "            node_idx_map[batch_mask] = torch.arange(num_nodes, device=device)\n",
    "            batch_edges = node_idx_map[batch_edges]\n",
    "\n",
    "            # Determine subgraph size\n",
    "            size_ratio = random.uniform(*self.subgraph_size_range)\n",
    "            subgraph_size = max(4, int(num_nodes * size_ratio))\n",
    "\n",
    "            # Select seed node and grow subgraph\n",
    "            if num_nodes > 0:\n",
    "                seed = random.randint(0, num_nodes - 1)\n",
    "                subgraph_nodes = self.grow_subgraph(\n",
    "                    batch_edges,\n",
    "                    num_nodes,\n",
    "                    seed,\n",
    "                    subgraph_size\n",
    "                )\n",
    "\n",
    "                # Create mask for this batch\n",
    "                mask = torch.zeros(num_nodes, device=device, dtype=torch.bool)\n",
    "                mask[subgraph_nodes] = True\n",
    "            else:\n",
    "                mask = torch.zeros(num_nodes, device=device, dtype=torch.bool)\n",
    "\n",
    "            subgraph_masks.append(mask)\n",
    "\n",
    "        # Combine masks\n",
    "        final_mask = torch.cat(subgraph_masks)\n",
    "\n",
    "        # Apply to graph\n",
    "        subgraph_x = x[final_mask]\n",
    "        edge_mask = final_mask[edge_index[0]] & final_mask[edge_index[1]]\n",
    "        subgraph_edge_index = edge_index[:, edge_mask]\n",
    "        subgraph_edge_attr = edge_attr[edge_mask]\n",
    "\n",
    "        return subgraph_x, subgraph_edge_index, subgraph_edge_attr, final_mask\n",
    "\n",
    "    def forward(self, data, noise):\n",
    "        \"\"\"Fixed generator forward pass\"\"\"\n",
    "        device = data.x.device\n",
    "        batch = data.batch\n",
    "        batch_size = int(batch.max().item() + 1)\n",
    "\n",
    "        # Calculate nodes per graph\n",
    "        nodes_per_graph = torch.bincount(batch)\n",
    "        max_nodes = nodes_per_graph.max().item()\n",
    "\n",
    "        # Create noise for each node\n",
    "        expanded_noise = []\n",
    "        for i in range(batch_size):\n",
    "            # Get number of nodes for this graph\n",
    "            num_nodes = nodes_per_graph[i]\n",
    "            # Repeat noise vector for each node\n",
    "            graph_noise = noise[i:i+1].repeat(num_nodes, 1)\n",
    "            expanded_noise.append(graph_noise)\n",
    "\n",
    "        noise_expanded = torch.cat(expanded_noise, dim=0)\n",
    "\n",
    "        # Concatenate features with noise\n",
    "        x = torch.cat([data.x, noise_expanded], dim=1)\n",
    "        x = self.node_encoder(x)\n",
    "\n",
    "        # Apply graph convolutions\n",
    "        x1 = F.relu(self.graph_conv1(x, data.edge_index))\n",
    "        x2 = F.relu(self.graph_conv2(x1, data.edge_index))\n",
    "        x3 = self.graph_conv3(x2, data.edge_index)\n",
    "\n",
    "        # Node features\n",
    "        x_final = self.node_decoder(x3)\n",
    "\n",
    "        return Data(\n",
    "            x=x_final,\n",
    "            edge_index=data.edge_index.clone(),\n",
    "            edge_attr=data.edge_attr.clone(),\n",
    "            batch=batch\n",
    "        )\n",
    "\n",
    "class CrossGraphAttention(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.query_transform = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.key_transform = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.value_transform = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.attention_scale = hidden_dim ** -0.5\n",
    "        \n",
    "    def forward(self, x1, x2, batch1, batch2):\n",
    "        Q = self.query_transform(x1)  # [N1, H]\n",
    "        K = self.key_transform(x2)    # [N2, H]\n",
    "        V = self.value_transform(x2)  # [N2, H]\n",
    "        \n",
    "        # Compute attention scores\n",
    "        attention = torch.matmul(Q, K.transpose(-2, -1)) * self.attention_scale\n",
    "        \n",
    "        # Create attention mask based on batch assignments\n",
    "        mask = batch1.unsqueeze(-1) == batch2.unsqueeze(-2)  # [N1, N2]\n",
    "        attention = attention.masked_fill(~mask, float('-inf'))\n",
    "        \n",
    "        # Normalize attention weights\n",
    "        attention = F.softmax(attention, dim=-1)\n",
    "        \n",
    "        # Apply attention to values\n",
    "        out = torch.matmul(attention, V)\n",
    "        return out    \n",
    "    \n",
    "class HierarchicalDiscriminator(nn.Module):\n",
    "    def __init__(self, num_atom_features, num_bond_features, hidden_dim=128):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # Node-level encoders\n",
    "        self.node_encoder_real = nn.Sequential(\n",
    "            nn.Linear(num_atom_features, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim)\n",
    "        )\n",
    "        \n",
    "        self.node_encoder_gen = nn.Sequential(\n",
    "            nn.Linear(num_atom_features, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim)\n",
    "        )\n",
    "        \n",
    "        # Edge-level encoders\n",
    "        self.edge_encoder_real = nn.Sequential(\n",
    "            nn.Linear(num_bond_features, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim)\n",
    "        )\n",
    "        \n",
    "        self.edge_encoder_gen = nn.Sequential(\n",
    "            nn.Linear(num_bond_features, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim)\n",
    "        )\n",
    "        \n",
    "        # Multi-scale graph convolutions\n",
    "        self.local_conv_real = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.local_conv_gen = GCNConv(hidden_dim, hidden_dim)\n",
    "        \n",
    "        self.meso_conv_real = SAGEConv(hidden_dim, hidden_dim)\n",
    "        self.meso_conv_gen = SAGEConv(hidden_dim, hidden_dim)\n",
    "        \n",
    "        self.global_conv_real = GATConv(hidden_dim, hidden_dim)\n",
    "        self.global_conv_gen = GATConv(hidden_dim, hidden_dim)\n",
    "        \n",
    "        # Cross-graph attention modules\n",
    "        self.cross_attention_local = CrossGraphAttention(hidden_dim)\n",
    "        self.cross_attention_meso = CrossGraphAttention(hidden_dim)\n",
    "        self.cross_attention_global = CrossGraphAttention(hidden_dim)\n",
    "        \n",
    "        # Feature fusion\n",
    "        self.fusion = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 6, hidden_dim * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, data_real, data_gen):\n",
    "        # Process real graph\n",
    "        x_real = self.node_encoder_real(data_real.x)\n",
    "        edge_real = self.edge_encoder_real(data_real.edge_attr)\n",
    "        \n",
    "        # Process generated graph\n",
    "        x_gen = self.node_encoder_gen(data_gen.x)\n",
    "        edge_gen = self.edge_encoder_gen(data_gen.edge_attr)\n",
    "        \n",
    "        # Multi-scale features for real graph\n",
    "        local_real = F.relu(self.local_conv_real(x_real, data_real.edge_index))\n",
    "        meso_real = F.relu(self.meso_conv_real(local_real, data_real.edge_index))\n",
    "        global_real = self.global_conv_real(meso_real, data_real.edge_index)\n",
    "        \n",
    "        # Multi-scale features for generated graph\n",
    "        local_gen = F.relu(self.local_conv_gen(x_gen, data_gen.edge_index))\n",
    "        meso_gen = F.relu(self.meso_conv_gen(local_gen, data_gen.edge_index))\n",
    "        global_gen = self.global_conv_gen(meso_gen, data_gen.edge_index)\n",
    "        \n",
    "        # Cross-graph attention at each scale\n",
    "        local_attended = self.cross_attention_local(local_real, local_gen, \n",
    "                                                  data_real.batch, data_gen.batch)\n",
    "        meso_attended = self.cross_attention_meso(meso_real, meso_gen,\n",
    "                                                data_real.batch, data_gen.batch)\n",
    "        global_attended = self.cross_attention_global(global_real, global_gen,\n",
    "                                                    data_real.batch, data_gen.batch)\n",
    "        \n",
    "        # Pool features\n",
    "        local_pool_real = global_add_pool(local_attended, data_real.batch)\n",
    "        meso_pool_real = global_mean_pool(meso_attended, data_real.batch)\n",
    "        global_pool_real = global_mean_pool(global_attended, data_real.batch)\n",
    "        \n",
    "        local_pool_gen = global_add_pool(local_gen, data_gen.batch)\n",
    "        meso_pool_gen = global_mean_pool(meso_gen, data_gen.batch)\n",
    "        global_pool_gen = global_mean_pool(global_gen, data_gen.batch)\n",
    "        \n",
    "        # Concatenate all pooled features\n",
    "        combined = torch.cat([\n",
    "            local_pool_real, local_pool_gen,\n",
    "            meso_pool_real, meso_pool_gen,\n",
    "            global_pool_real, global_pool_gen\n",
    "        ], dim=1)\n",
    "        \n",
    "        # Final discriminator output\n",
    "        return torch.sigmoid(self.fusion(combined))\n",
    "\n",
    "    def compute_structural_similarity(self, x1, x2, edge_index1, edge_index2):\n",
    "        num_nodes1 = x1.size(0)\n",
    "        num_nodes2 = x2.size(0)\n",
    "        node_diff = abs(x1.mean(dim=0) - x2.mean(dim=0)).mean()\n",
    "        edge_diff = abs(edge_index1.size(1) / max(num_nodes1, 1) - \n",
    "                       edge_index2.size(1) / max(num_nodes2, 1))\n",
    "        return torch.exp(-(node_diff + edge_diff))\n",
    "\n",
    "def process_batch_graphs(batch):\n",
    "    \"\"\"Process a batch of graphs and return individual graph objects\"\"\"\n",
    "    processed_graphs = []\n",
    "    batch_size = batch.num_graphs\n",
    "    \n",
    "    for idx in range(batch_size):\n",
    "        # Get mask for current graph\n",
    "        mask = (batch.batch == idx)\n",
    "        \n",
    "        # Extract subgraph\n",
    "        x = batch.x[mask]\n",
    "        \n",
    "        # Get edge mask\n",
    "        edge_mask = mask[batch.edge_index[0]] & mask[batch.edge_index[1]]\n",
    "        edge_index = batch.edge_index[:, edge_mask]\n",
    "        edge_attr = batch.edge_attr[edge_mask]\n",
    "        \n",
    "        # Adjust edge indices to local indexing\n",
    "        node_map = torch.zeros(mask.size(0), dtype=torch.long, device=edge_index.device)\n",
    "        node_map[mask] = torch.arange(mask.sum(), device=edge_index.device)\n",
    "        edge_index = node_map[edge_index]\n",
    "        \n",
    "        # Create new Data object\n",
    "        graph = Data(\n",
    "            x=x,\n",
    "            edge_index=edge_index,\n",
    "            edge_attr=edge_attr\n",
    "        )\n",
    "        processed_graphs.append(graph)\n",
    "    \n",
    "    return processed_graphs\n",
    "\n",
    "\n",
    "def structural_consistency_loss(real_graphs, gen_graphs):\n",
    "    \"\"\"Enhanced structural consistency loss with proper dimension handling\"\"\"\n",
    "    device = real_graphs.x.device\n",
    "    batch_size = int(real_graphs.batch.max().item()) + 1\n",
    "    \n",
    "    # Node feature distribution matching per batch\n",
    "    node_losses = []\n",
    "    for b in range(batch_size):\n",
    "        real_mask = (real_graphs.batch == b)\n",
    "        gen_mask = (gen_graphs.batch == b)\n",
    "        \n",
    "        if real_mask.sum() > 0 and gen_mask.sum() > 0:\n",
    "            # Get batch features and compute stats\n",
    "            real_batch_features = real_graphs.x[real_mask]\n",
    "            gen_batch_features = gen_graphs.x[gen_mask]\n",
    "            \n",
    "            # Normalize features before comparison\n",
    "            real_stats = F.normalize(torch.mean(real_batch_features, dim=0), dim=0)\n",
    "            gen_stats = F.normalize(torch.mean(gen_batch_features, dim=0), dim=0)\n",
    "            \n",
    "            # Ensure same dimension by projection if needed\n",
    "            if real_stats.size(0) != gen_stats.size(0):\n",
    "                min_dim = min(real_stats.size(0), gen_stats.size(0))\n",
    "                real_stats = real_stats[:min_dim]\n",
    "                gen_stats = gen_stats[:min_dim]\n",
    "            \n",
    "            node_losses.append(F.mse_loss(real_stats, gen_stats))\n",
    "    \n",
    "    node_loss = torch.mean(torch.stack(node_losses)) if node_losses else torch.tensor(0.0, device=device)\n",
    "    \n",
    "    # Edge attribute distribution matching\n",
    "    edge_losses = []\n",
    "    for b in range(batch_size):\n",
    "        real_edge_mask = (real_graphs.batch[real_graphs.edge_index[0]] == b)\n",
    "        gen_edge_mask = (gen_graphs.batch[gen_graphs.edge_index[0]] == b)\n",
    "        \n",
    "        if real_edge_mask.sum() > 0 and gen_edge_mask.sum() > 0:\n",
    "            real_edges = real_graphs.edge_attr[real_edge_mask]\n",
    "            gen_edges = gen_graphs.edge_attr[gen_edge_mask]\n",
    "            \n",
    "            # Compute and normalize edge statistics\n",
    "            real_edge_stats = F.normalize(torch.mean(real_edges, dim=0), dim=0)\n",
    "            gen_edge_stats = F.normalize(torch.mean(gen_edges, dim=0), dim=0)\n",
    "            \n",
    "            edge_losses.append(F.mse_loss(real_edge_stats, gen_edge_stats))\n",
    "    \n",
    "    edge_loss = torch.mean(torch.stack(edge_losses)) if edge_losses else torch.tensor(0.0, device=device)\n",
    "    \n",
    "    # Graph density matching with proper handling\n",
    "    density_losses = []\n",
    "    for b in range(batch_size):\n",
    "        real_mask = (real_graphs.batch == b)\n",
    "        gen_mask = (gen_graphs.batch == b)\n",
    "        \n",
    "        if real_mask.sum() > 0 and gen_mask.sum() > 0:\n",
    "            # Compute edge densities\n",
    "            real_edge_mask = (real_graphs.batch[real_graphs.edge_index[0]] == b)\n",
    "            gen_edge_mask = (gen_graphs.batch[gen_graphs.edge_index[0]] == b)\n",
    "            \n",
    "            real_num_nodes = real_mask.sum().float()\n",
    "            gen_num_nodes = gen_mask.sum().float()\n",
    "            \n",
    "            real_num_edges = real_edge_mask.sum().float()\n",
    "            gen_num_edges = gen_edge_mask.sum().float()\n",
    "            \n",
    "            real_density = real_num_edges / (real_num_nodes * real_num_nodes + 1e-6)\n",
    "            gen_density = gen_num_edges / (gen_num_nodes * gen_num_nodes + 1e-6)\n",
    "            \n",
    "            density_losses.append(torch.abs(real_density - gen_density))\n",
    "    \n",
    "    density_loss = torch.mean(torch.stack(density_losses)) if density_losses else torch.tensor(0.0, device=device)\n",
    "    \n",
    "    # Combine losses with weights\n",
    "    total_loss = node_loss + 0.5 * edge_loss + 0.3 * density_loss\n",
    "    \n",
    "    return total_loss.to(device)\n",
    "\n",
    "def wasserstein_loss(real_scores, fake_scores, gp_weight=10.0):\n",
    "    \"\"\"Wasserstein loss with gradient penalty\"\"\"\n",
    "    # Basic Wasserstein loss\n",
    "    w_loss = -torch.mean(real_scores) + torch.mean(fake_scores)\n",
    "    \n",
    "    return w_loss\n",
    "\n",
    "def get_batch_size(batch_data):\n",
    "    \"\"\"Helper function to get the number of graphs in a batch\"\"\"\n",
    "    return int(batch_data.batch.max().item() + 1)\n",
    "\n",
    "def hierarchical_discriminator_loss(discriminator, real_graphs, gen_graphs, validity_weight=0.1):\n",
    "    \"\"\"Compute discriminator loss with proper tensor size handling\"\"\"\n",
    "    # Get batch sizes from batch tensor\n",
    "    real_batch_size = int(real_graphs.batch.max().item() + 1)\n",
    "    gen_batch_size = int(gen_graphs.batch.max().item() + 1)\n",
    "    \n",
    "    # Compute discriminator scores\n",
    "    real_scores = discriminator(real_graphs, real_graphs)\n",
    "    fake_scores = discriminator(real_graphs, gen_graphs)\n",
    "    \n",
    "    # Wasserstein loss\n",
    "    d_loss = -(torch.mean(real_scores) - torch.mean(fake_scores))\n",
    "    \n",
    "    # Compute structural consistency\n",
    "    struct_loss = structural_consistency_loss(real_graphs, gen_graphs)\n",
    "    \n",
    "    \n",
    "    return d_loss + validity_loss + 0.5 * struct_loss\n",
    "\n",
    "def scatter_add_alternative(src, index, dim_size=None):\n",
    "    \"\"\"Alternative implementation of scatter_add without using torch_scatter\"\"\"\n",
    "    if dim_size is None:\n",
    "        dim_size = index.max().item() + 1\n",
    "    result = torch.zeros(dim_size, dtype=src.dtype, device=src.device)\n",
    "    result.index_add_(0, index, src)\n",
    "    return result\n",
    "\n",
    "def scatter_mean_alternative(src, index, dim_size=None):\n",
    "    \"\"\"Alternative implementation of scatter_mean without using torch_scatter\"\"\"\n",
    "    if dim_size is None:\n",
    "        dim_size = index.max().item() + 1\n",
    "    \n",
    "    # Sum values\n",
    "    sum_result = scatter_add_alternative(src, index, dim_size)\n",
    "    \n",
    "    # Count occurrences of each index\n",
    "    ones = torch.ones_like(src)\n",
    "    count = scatter_add_alternative(ones, index, dim_size)\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    count = torch.clamp(count, min=1)\n",
    "    \n",
    "    return sum_result / count\n",
    "\n",
    "def compute_structural_similarity_alternative(x1, x2, edge_index1, edge_index2):\n",
    "    \"\"\"Compute structural similarity with normalized metrics\"\"\"\n",
    "    device = x1.device\n",
    "    \n",
    "    # Ensure same feature dimensions by projection if needed\n",
    "    if x1.size(1) != x2.size(1):\n",
    "        # Project the smaller dimension to the larger one\n",
    "        if x1.size(1) < x2.size(1):\n",
    "            projection = nn.Linear(x1.size(1), x2.size(1)).to(device)\n",
    "            x1 = projection(x1)\n",
    "        else:\n",
    "            projection = nn.Linear(x2.size(1), x1.size(1)).to(device)\n",
    "            x2 = projection(x2)\n",
    "    \n",
    "    # Compare node features using normalized means and improved similarity metric\n",
    "    x1_mean = F.normalize(x1.mean(dim=0, keepdim=True), dim=1)\n",
    "    x2_mean = F.normalize(x2.mean(dim=0, keepdim=True), dim=1)\n",
    "    node_sim = (F.cosine_similarity(x1_mean, x2_mean).mean() + 1) / 2  # Scale to [0,1]\n",
    "    \n",
    "    # Compare graph structure with normalized metrics\n",
    "    n1 = torch.tensor(x1.size(0), dtype=torch.float, device=device)\n",
    "    n2 = torch.tensor(x2.size(0), dtype=torch.float, device=device)\n",
    "    e1 = torch.tensor(edge_index1.size(1), dtype=torch.float, device=device)\n",
    "    e2 = torch.tensor(edge_index2.size(1), dtype=torch.float, device=device)\n",
    "    \n",
    "    edge_density1 = e1 / (n1 * n1)\n",
    "    edge_density2 = e2 / (n2 * n2)\n",
    "    \n",
    "    # Normalized edge similarity\n",
    "    max_density = torch.max(edge_density1, edge_density2)\n",
    "    min_density = torch.min(edge_density1, edge_density2)\n",
    "    edge_sim = min_density / (max_density + 1e-6)\n",
    "    \n",
    "    # Weighted combination with adjusted weights\n",
    "    similarity = 0.6 * node_sim + 0.4 * edge_sim\n",
    "    \n",
    "    return similarity\n",
    "\n",
    "def compute_degree_distribution(edge_index, num_nodes):\n",
    "    \"\"\"Compute degree distribution without scatter operations\"\"\"\n",
    "    degrees = torch.zeros(num_nodes, device=edge_index.device)\n",
    "    unique_nodes, counts = torch.unique(edge_index[0], return_counts=True)\n",
    "    degrees[unique_nodes] = counts.float()\n",
    "    return degrees\n",
    "\n",
    "def approximate_clustering_alternative(edge_index, num_nodes):\n",
    "    \"\"\"Alternative implementation of clustering coefficient approximation\"\"\"\n",
    "    # Convert edge_index to adjacency list format for efficiency\n",
    "    adj_list = [[] for _ in range(num_nodes)]\n",
    "    for i in range(edge_index.size(1)):\n",
    "        node1, node2 = edge_index[:, i]\n",
    "        adj_list[node1].append(node2)\n",
    "    \n",
    "    clustering_coeffs = []\n",
    "    max_samples = min(num_nodes, 1000)  # Limit computation\n",
    "    \n",
    "    # Sample nodes for approximation\n",
    "    sampled_nodes = torch.randperm(num_nodes)[:max_samples]\n",
    "    \n",
    "    for node in sampled_nodes:\n",
    "        neighbors = adj_list[node]\n",
    "        if len(neighbors) < 2:\n",
    "            clustering_coeffs.append(0)\n",
    "            continue\n",
    "            \n",
    "        # Count triangles\n",
    "        triangles = 0\n",
    "        potential_triangles = len(neighbors) * (len(neighbors) - 1) / 2\n",
    "        \n",
    "        if potential_triangles > 0:\n",
    "            for i in range(len(neighbors)):\n",
    "                for j in range(i + 1, len(neighbors)):\n",
    "                    if neighbors[j] in adj_list[neighbors[i]]:\n",
    "                        triangles += 1\n",
    "            \n",
    "            clustering_coeffs.append(triangles / potential_triangles)\n",
    "    \n",
    "    if clustering_coeffs:\n",
    "        return torch.tensor(sum(clustering_coeffs) / len(clustering_coeffs), \n",
    "                          device=edge_index.device)\n",
    "    return torch.tensor(0., device=edge_index.device)\n",
    "\n",
    "def compute_graph_stats(graphs):\n",
    "    stats = []\n",
    "    for g in graphs:\n",
    "        num_nodes = g.x.size(0)\n",
    "        degrees = compute_degree_distribution(g.edge_index, num_nodes)\n",
    "        avg_degree = degrees.mean()\n",
    "        clustering = approximate_clustering_alternative(g.edge_index, num_nodes)\n",
    "        density = (2 * g.edge_index.size(1)) / (num_nodes * (num_nodes - 1) + 1e-6)\n",
    "        stats.append(torch.stack([avg_degree, clustering, density]))\n",
    "    return torch.stack(stats).mean(dim=0)\n",
    "\n",
    "\n",
    "def approximate_clustering(edge_index):\n",
    "    \"\"\"\n",
    "    Approximate clustering coefficient for efficiency\n",
    "    \"\"\"\n",
    "    # Simple approximation based on triangle counting\n",
    "    row, col = edge_index\n",
    "    deg = scatter_add(torch.ones_like(row), row)\n",
    "    \n",
    "    # Count triangles (approximate)\n",
    "    triangles = torch.zeros_like(deg.float())\n",
    "    for i in range(min(len(row), 1000)):  # Limit computation for efficiency\n",
    "        neighbors = col[row == row[i]]\n",
    "        if len(neighbors) > 1:\n",
    "            triangles[row[i]] += torch.sum(torch.isin(col[row == neighbors[0]], neighbors[1:]))\n",
    "    \n",
    "    return triangles.mean()\n",
    "\n",
    "\n",
    "def validity_penalty(data_gen):\n",
    "    \"\"\"Simplified validity check\"\"\"\n",
    "    validity_score = torch.tensor(0.0)\n",
    "    try:\n",
    "#         validity_score = compute_chemical_validity(data_gen)\n",
    "        validity_score = 1\n",
    "    except:\n",
    "        pass\n",
    "    return 1 - validity_score\n",
    "\n",
    "class EnhancedGraphSoftmax(nn.Module):\n",
    "    def __init__(self, hidden_dim, num_heads=4, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = hidden_dim // num_heads\n",
    "        self.scaling = self.head_dim ** -0.5\n",
    "        \n",
    "        # Multi-head projections\n",
    "        self.q_proj = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.k_proj = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.v_proj = nn.Linear(hidden_dim, hidden_dim)\n",
    "        \n",
    "        # Dynamic temperature\n",
    "        self.temperature = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 1),\n",
    "            nn.Softplus()\n",
    "        )\n",
    "        \n",
    "        # Edge-aware attention\n",
    "        self.edge_gate = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        self.output_proj = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.layer_norm = nn.LayerNorm(hidden_dim)\n",
    "        \n",
    "    def forward(self, x, edge_index, batch):\n",
    "        N = x.size(0)\n",
    "        num_batches = int(batch.max()) + 1\n",
    "        \n",
    "        # Multi-head projections\n",
    "        q = self.q_proj(x).view(N, self.num_heads, self.head_dim)\n",
    "        k = self.k_proj(x).view(N, self.num_heads, self.head_dim)\n",
    "        v = self.v_proj(x).view(N, self.num_heads, self.head_dim)\n",
    "        \n",
    "        # Compute attention scores per batch\n",
    "        outputs = []\n",
    "        for b in range(num_batches):\n",
    "            batch_mask = (batch == b)\n",
    "            \n",
    "            # Get batch features\n",
    "            q_b = q[batch_mask]\n",
    "            k_b = k[batch_mask]\n",
    "            v_b = v[batch_mask]\n",
    "            \n",
    "            if q_b.size(0) == 0:\n",
    "                continue\n",
    "                \n",
    "            # Compute attention scores for this batch\n",
    "            attn_b = torch.matmul(q_b, k_b.transpose(-2, -1)) * self.scaling\n",
    "            \n",
    "            # Compute temperature for this batch\n",
    "            batch_features = x[batch_mask]\n",
    "            batch_mean = torch.mean(batch_features, dim=0, keepdim=True)\n",
    "            batch_max, _ = torch.max(batch_features, dim=0, keepdim=True)\n",
    "            temp_input = torch.cat([batch_mean, batch_max], dim=-1)\n",
    "            temp = self.temperature(temp_input)\n",
    "            \n",
    "            # Apply temperature scaling\n",
    "            attn_b = attn_b / (temp + 1e-6)\n",
    "            \n",
    "            # Apply attention masking and softmax\n",
    "            attn_b = F.softmax(attn_b, dim=-1)\n",
    "            attn_b = self.dropout(attn_b)\n",
    "            \n",
    "            # Compute output for this batch\n",
    "            out_b = torch.matmul(attn_b, v_b)\n",
    "            outputs.append(out_b)\n",
    "        \n",
    "        # Combine batch outputs\n",
    "        if not outputs:\n",
    "            return x  # Return input if no valid batches\n",
    "        \n",
    "        out = torch.cat(outputs, dim=0)\n",
    "        out = out.view(out.size(0), -1)  # Flatten the heads\n",
    "        \n",
    "        # Edge-aware attention\n",
    "        if edge_index.size(1) > 0:\n",
    "            edge_features = torch.cat([x[edge_index[0]], x[edge_index[1]]], dim=-1)\n",
    "            edge_weights = self.edge_gate(edge_features)\n",
    "            edge_weights = scatter_softmax(edge_weights, edge_index[1], dim=0)\n",
    "            edge_attention = scatter_add(\n",
    "                x[edge_index[0]] * edge_weights, edge_index[1], dim=0, dim_size=N\n",
    "            )\n",
    "            out = out + edge_attention\n",
    "        \n",
    "        # Output projection with residual connection and normalization\n",
    "        out = self.output_proj(out)\n",
    "        out = self.layer_norm(out + x)\n",
    "        \n",
    "        return out\n",
    "\n",
    "class EnhancedVertexConnectivity(nn.Module):\n",
    "    def __init__(self, hidden_dim, num_layers=3):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # Multi-scale graph convolutions with attention\n",
    "        self.graph_layers = nn.ModuleList([\n",
    "            GATConv(hidden_dim, hidden_dim // 8, heads=8)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        \n",
    "        # Layer normalization\n",
    "        self.layer_norms = nn.ModuleList([\n",
    "            nn.LayerNorm(hidden_dim) for _ in range(num_layers)\n",
    "        ])\n",
    "        \n",
    "        # Adaptive edge sampling\n",
    "        self.edge_importance = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        # Structure-aware prediction\n",
    "        self.struct_encoder = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim)\n",
    "        )\n",
    "        \n",
    "        # Edge prediction with attention\n",
    "        self.edge_attention = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 3, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # Multi-scale feature extraction\n",
    "        h = x\n",
    "        intermediate_features = []\n",
    "        \n",
    "        for conv, norm in zip(self.graph_layers, self.layer_norms):\n",
    "            # Graph attention convolution\n",
    "            h_conv = conv(h, edge_index)\n",
    "            # Residual connection and normalization\n",
    "            h = norm(h + h_conv)\n",
    "            h = F.relu(h)\n",
    "            intermediate_features.append(h)\n",
    "        \n",
    "        # Structure encoding\n",
    "        struct_feats = self.struct_encoder(h)\n",
    "        \n",
    "        # Edge importance scoring\n",
    "        edge_src, edge_dst = edge_index\n",
    "        edge_feats = torch.cat([\n",
    "            struct_feats[edge_src],\n",
    "            struct_feats[edge_dst],\n",
    "            torch.abs(struct_feats[edge_src] - struct_feats[edge_dst])\n",
    "        ], dim=-1)\n",
    "        \n",
    "        # Compute edge attention scores\n",
    "        edge_scores = self.edge_attention(edge_feats)\n",
    "        edge_attention = scatter_softmax(edge_scores, edge_dst, dim=0)\n",
    "        \n",
    "        # Combine with structure features\n",
    "        edge_preds = edge_attention * self.edge_importance(\n",
    "            torch.cat([struct_feats[edge_src], struct_feats[edge_dst]], dim=-1)\n",
    "        )\n",
    "        \n",
    "        return edge_preds, struct_feats, edge_attention\n",
    "\n",
    "class EnhancedGraphGAN(nn.Module):\n",
    "    def __init__(self, num_features, hidden_dim, num_heads=4):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Enhanced components\n",
    "        self.softmax = EnhancedGraphSoftmax(hidden_dim, num_heads)\n",
    "        self.connectivity = EnhancedVertexConnectivity(hidden_dim)\n",
    "        \n",
    "        # Feature embedding with positional encoding\n",
    "        self.node_embedding = nn.Sequential(\n",
    "            nn.Linear(num_features, hidden_dim),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1)\n",
    "        )\n",
    "        \n",
    "        # Generator with residual blocks\n",
    "        self.generator = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(hidden_dim, hidden_dim),\n",
    "                nn.LayerNorm(hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.1),\n",
    "                nn.Linear(hidden_dim, hidden_dim)\n",
    "            ) for _ in range(3)\n",
    "        ])\n",
    "        \n",
    "        # Multi-scale discriminator\n",
    "        self.discriminator = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(hidden_dim, hidden_dim),\n",
    "                nn.LayerNorm(hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.1),\n",
    "                nn.Linear(hidden_dim, hidden_dim // 2)\n",
    "            ) for _ in range(3)\n",
    "        ])\n",
    "        \n",
    "        self.disc_output = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 3 // 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # Node embeddings with positional information\n",
    "        h = self.node_embedding(x)\n",
    "        \n",
    "        # Enhanced graph softmax\n",
    "        h_soft = self.softmax(h, edge_index, batch)\n",
    "        \n",
    "        # Generate fake samples with residual connections\n",
    "        fake_h = h_soft\n",
    "        for gen_layer in self.generator:\n",
    "            fake_h = fake_h + gen_layer(fake_h)\n",
    "        \n",
    "        # Multi-scale discrimination\n",
    "        real_features = []\n",
    "        fake_features = []\n",
    "        \n",
    "        for disc_layer in self.discriminator:\n",
    "            real_feat = disc_layer(h_soft)\n",
    "            fake_feat = disc_layer(fake_h)\n",
    "            real_features.append(scatter_mean(real_feat, batch, dim=0))\n",
    "            fake_features.append(scatter_mean(fake_feat, batch, dim=0))\n",
    "        \n",
    "        # Combine features for final discrimination\n",
    "        real_combined = torch.cat(real_features, dim=1)\n",
    "        fake_combined = torch.cat(fake_features, dim=1)\n",
    "        \n",
    "        real_scores = self.disc_output(real_combined)\n",
    "        fake_scores = self.disc_output(fake_combined)\n",
    "        \n",
    "        # Get connectivity predictions\n",
    "        pred, struct_feats, edge_attn = self.connectivity(h_soft, edge_index, batch)\n",
    "        \n",
    "        return real_scores, fake_scores, pred, h_soft\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b53b5ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveEncoder(nn.Module):\n",
    "    def __init__(self, node_dim, edge_dim, hidden_dim, output_dim, num_layers=3):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # Adaptive node encoder to handle varying input dimensions\n",
    "        self.node_encoder = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),  # Changed from node_dim to hidden_dim\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(hidden_dim, hidden_dim)\n",
    "        )\n",
    "        \n",
    "        # Input projection layer to handle varying input dimensions\n",
    "        self.input_proj = nn.Linear(node_dim, hidden_dim)\n",
    "        \n",
    "        self.edge_encoder = nn.Sequential(\n",
    "            nn.Linear(edge_dim, hidden_dim),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(hidden_dim, hidden_dim)\n",
    "        )\n",
    "        \n",
    "        # Multi-scale graph convolutions\n",
    "        self.convs = nn.ModuleList([\n",
    "            GCNConv(hidden_dim, hidden_dim) for _ in range(num_layers)\n",
    "        ])\n",
    "        \n",
    "        self.layer_norms = nn.ModuleList([\n",
    "            nn.LayerNorm(hidden_dim) for _ in range(num_layers)\n",
    "        ])\n",
    "        \n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "        \n",
    "        self.output = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, edge_index, edge_attr, batch):\n",
    "        # Project input features to hidden dimension if necessary\n",
    "        if x.size(1) != self.hidden_dim:\n",
    "            x = self.input_proj(x)\n",
    "        \n",
    "        # Enhanced node and edge encoding\n",
    "        x = self.node_encoder(x)\n",
    "        edge_features = self.edge_encoder(edge_attr)\n",
    "        \n",
    "        # Multi-scale feature extraction with residual connections\n",
    "        previous_x = x\n",
    "        for conv, norm in zip(self.convs, self.layer_norms):\n",
    "            # Message passing with edge features\n",
    "            conv_out = conv(x, edge_index)\n",
    "            # Edge feature influence\n",
    "            edge_influence = scatter_mean(edge_features, edge_index[0], dim=0, dim_size=x.size(0))\n",
    "            # Combine and normalize\n",
    "            x = norm(conv_out + edge_influence + previous_x)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=0.1, training=self.training)\n",
    "            previous_x = x\n",
    "        \n",
    "        # Attention-weighted pooling\n",
    "        attention_weights = self.attention(x)\n",
    "        attention_weights = scatter_softmax(attention_weights, batch, dim=0)\n",
    "        pooled_attention = scatter_add(x * attention_weights, batch, dim=0)\n",
    "        \n",
    "        # Global mean pooling\n",
    "        pooled_mean = scatter_mean(x, batch, dim=0)\n",
    "        \n",
    "        # Combine different pooling strategies\n",
    "        pooled = torch.cat([pooled_attention, pooled_mean], dim=-1)\n",
    "        \n",
    "        # Final projection\n",
    "        out = self.output(pooled)\n",
    "        return F.normalize(out, dim=1)\n",
    "\n",
    "    def encode_batch(self, batch_data):\n",
    "        \"\"\"Helper method to encode a batch of data\"\"\"\n",
    "        return self.forward(\n",
    "            batch_data.x,\n",
    "            batch_data.edge_index,\n",
    "            batch_data.edge_attr,\n",
    "            batch_data.batch\n",
    "        )\n",
    "\n",
    "def contrastive_loss(real_embeddings, gen_embeddings, temperature=0.5, margin=0.5):\n",
    "    \"\"\"Enhanced contrastive loss with hard negative mining and margin\"\"\"\n",
    "    batch_size = real_embeddings.size(0)\n",
    "    device = real_embeddings.device\n",
    "    \n",
    "    # Normalize embeddings\n",
    "    z_i = F.normalize(real_embeddings, dim=1)\n",
    "    z_j = F.normalize(gen_embeddings, dim=1)\n",
    "    \n",
    "    # Compute similarity matrix\n",
    "    similarity_matrix = torch.matmul(z_i, z_j.T)  # [batch_size, batch_size]\n",
    "    \n",
    "    # Positive pairs - diagonal elements\n",
    "    positive_pairs = torch.diag(similarity_matrix)\n",
    "    \n",
    "    # Hard negative mining\n",
    "    negative_pairs, _ = torch.topk(similarity_matrix - 2 * torch.eye(batch_size, device=device), k=3, dim=1)\n",
    "    hardest_negative = negative_pairs[:, 0]  # Take the most similar negative\n",
    "    \n",
    "    # InfoNCE loss with margin\n",
    "    pos_term = -torch.mean(positive_pairs) / temperature\n",
    "    neg_term = torch.mean(torch.log(1 + torch.exp((hardest_negative - margin) / temperature)))\n",
    "    \n",
    "    # Regularization term to maintain embedding diversity\n",
    "    diversity_reg = torch.mean(torch.abs(torch.matmul(z_i, z_i.T) - torch.eye(batch_size, device=device)))\n",
    "    \n",
    "    return pos_term + neg_term + 0.1 * diversity_reg\n",
    "\n",
    "def check_for_nans(tensor, name):\n",
    "    if torch.isnan(tensor).any() or torch.isinf(tensor).any():\n",
    "        print(f\"{name} contains NaN or Inf values.\")\n",
    "\n",
    "def round_up_to_multiple(number, multiple):\n",
    "    \"\"\"Round up to nearest multiple\"\"\"\n",
    "    return ((number + multiple - 1) // multiple) * multiple\n",
    "    \n",
    "# Pad edge indices\n",
    "def pad_edge_index(edge_index, current_nodes, target_size):\n",
    "    if edge_index.size(1) < target_size:\n",
    "        # Create self-loops for padding\n",
    "        num_pad = target_size - edge_index.size(1)\n",
    "        pad_indices = torch.arange(0, min(num_pad, current_nodes), device=edge_index.device)\n",
    "        pad_indices = pad_indices.repeat(2, (num_pad + current_nodes - 1) // current_nodes)[:, :num_pad]\n",
    "        return torch.cat([edge_index, pad_indices], dim=1)\n",
    "    return edge_index\n",
    "\n",
    "def match_tensor_sizes(real_data, gen_data):\n",
    "    \"\"\"Fixed tensor size matching function\"\"\"\n",
    "    device = real_data.x.device\n",
    "    \n",
    "    # Get maximum nodes across both real and generated data\n",
    "    real_nodes_per_graph = torch.bincount(real_data.batch)\n",
    "    gen_nodes_per_graph = torch.bincount(gen_data.batch)\n",
    "    max_nodes = max(real_nodes_per_graph.max(), gen_nodes_per_graph.max())\n",
    "    batch_size = len(real_nodes_per_graph)\n",
    "    \n",
    "    def pad_data(data, max_nodes):\n",
    "        # Create new padded tensors\n",
    "        padded_x = torch.zeros(batch_size * max_nodes, data.x.size(1), device=device)\n",
    "        padded_batch = torch.arange(batch_size, device=device).repeat_interleave(max_nodes)\n",
    "        \n",
    "        # Fill with actual data\n",
    "        current_idx = 0\n",
    "        for i in range(batch_size):\n",
    "            mask = (data.batch == i)\n",
    "            num_nodes = mask.sum()\n",
    "            if num_nodes > 0:\n",
    "                padded_x[i*max_nodes:i*max_nodes + num_nodes] = data.x[mask]\n",
    "        \n",
    "        # Handle edge indices and attributes\n",
    "        new_edge_indices = []\n",
    "        new_edge_attrs = []\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            mask = (data.batch == i)\n",
    "            edge_mask = mask[data.edge_index[0]] & mask[data.edge_index[1]]\n",
    "            \n",
    "            if edge_mask.sum() > 0:\n",
    "                local_edges = data.edge_index[:, edge_mask]\n",
    "                local_attrs = data.edge_attr[edge_mask]\n",
    "                \n",
    "                # Map node indices to new positions\n",
    "                node_mapper = torch.full((mask.size(0),), -1, device=device, dtype=torch.long)\n",
    "                node_mapper[mask] = torch.arange(mask.sum(), device=device)\n",
    "                \n",
    "                # Adjust indices for batch\n",
    "                offset = i * max_nodes\n",
    "                mapped_edges = node_mapper[local_edges] + offset\n",
    "                \n",
    "                # Only keep valid edges\n",
    "                valid_edges = (mapped_edges[0] >= 0) & (mapped_edges[1] >= 0)\n",
    "                new_edge_indices.append(mapped_edges[:, valid_edges])\n",
    "                new_edge_attrs.append(local_attrs[valid_edges])\n",
    "        \n",
    "        if new_edge_indices:\n",
    "            edge_index = torch.cat(new_edge_indices, dim=1)\n",
    "            edge_attr = torch.cat(new_edge_attrs, dim=0)\n",
    "        else:\n",
    "            edge_index = torch.empty((2, 0), device=device, dtype=torch.long)\n",
    "            edge_attr = torch.empty((0, data.edge_attr.size(1)), device=device)\n",
    "            \n",
    "        return Data(x=padded_x, edge_index=edge_index, edge_attr=edge_attr, batch=padded_batch)\n",
    "    \n",
    "    return pad_data(real_data, max_nodes), pad_data(gen_data, max_nodes)\n",
    "\n",
    "def process_batch(batch, generator, latent_dim, device):\n",
    "    \"\"\"Fixed batch processing\"\"\"\n",
    "    try:\n",
    "        batch = batch.to(device)\n",
    "        batch_size = int(batch.batch.max().item() + 1)\n",
    "        \n",
    "        # Generate latent vectors\n",
    "        z = torch.randn(batch_size, latent_dim, device=device)\n",
    "        \n",
    "        # Generate fake graphs with gradient disabled\n",
    "        with torch.no_grad():\n",
    "            fake_graphs = generator(batch, z)\n",
    "            \n",
    "        # Match sizes without breaking the graph structure\n",
    "        batch_matched, fake_graphs_matched = match_tensor_sizes(batch, fake_graphs)\n",
    "        \n",
    "        return batch_matched, fake_graphs_matched, batch_size\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing batch: {str(e)}\")\n",
    "        return None, None, None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6402abfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gan_cl_improved(smiles_df, num_epochs, batch_size=32, lr=1e-5, critic_iterations=5,\n",
    "                     lambda_cl=1.0, lambda_gen=0.8, lambda_disc=1.2):\n",
    "    \"\"\"Training loop balancing GAN quality with contrastive learning\"\"\"\n",
    "    dataset = MolecularGraphDataset(smiles_df['SMILES'].tolist())\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    # Initialize models and optimizers\n",
    "    node_dim = dataset.graphs[0].x.size(1)\n",
    "    edge_dim = dataset.graphs[0].edge_attr.size(1)\n",
    "    hidden_dim = 128\n",
    "    latent_dim = 64\n",
    "    contrastive_dim = 128\n",
    "    \n",
    "    graph_gan = EnhancedGraphGAN(\n",
    "        num_features=node_dim,\n",
    "        hidden_dim=hidden_dim\n",
    "    ).to(device)\n",
    "    \n",
    "    encoder = ContrastiveEncoder(\n",
    "        node_dim=node_dim,\n",
    "        edge_dim=edge_dim,\n",
    "        hidden_dim=hidden_dim,\n",
    "        output_dim=contrastive_dim\n",
    "    ).to(device)\n",
    "    \n",
    "    # Balanced learning rates for all components\n",
    "    g_optimizer = torch.optim.Adam(\n",
    "        filter(lambda p: p.requires_grad, graph_gan.generator.parameters()),\n",
    "        lr=lr * 0.8,  # Reduced generator learning rate\n",
    "        betas=(0.9, 0.999)\n",
    "    )\n",
    "    d_optimizer = torch.optim.Adam(\n",
    "        filter(lambda p: p.requires_grad, graph_gan.discriminator.parameters()),\n",
    "        lr=lr * 1.2, # Increased discriminator learning rate\n",
    "        betas=(0.9, 0.999)\n",
    "    )\n",
    "    e_optimizer = torch.optim.Adam(\n",
    "        encoder.parameters(), \n",
    "        lr=lr*1.5,  # Slightly higher for encoder but not overwhelming\n",
    "        betas=(0.9, 0.999)\n",
    "    )\n",
    "    \n",
    "    # Track both GAN and CL performance for early stopping\n",
    "    d_losses, g_losses, cl_losses = [], [], []\n",
    "    best_combined_loss = float('inf')\n",
    "    patience = 20\n",
    "    patience_counter = 0\n",
    "    \n",
    "    # Structural similarity threshold for augmentation quality\n",
    "    similarity_threshold = 0.3  # Reduced threshold for early learning\n",
    "    min_similarity_increase = 0.01  # Expected minimum improvement per epoch\n",
    "    adaptive_threshold = True  # Enable adaptive threshold\n",
    "    \n",
    "#     # Add learning rate schedulers\n",
    "#     g_scheduler = torch.optim.ReduceLROnPlateau(g_optimizer, mode='min', factor=0.5, patience=5)\n",
    "#     d_scheduler = torch.optim.ReduceLROnPlateau(d_optimizer, mode='min', factor=0.5, patience=5)\n",
    "    \n",
    "    # Initialize schedulers\n",
    "    g_scheduler = ReduceLROnPlateau(g_optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
    "    d_scheduler = ReduceLROnPlateau(d_optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
    "    \n",
    "    # Enhanced loss tracking\n",
    "    best_losses = {\n",
    "        'generator': float('inf'),\n",
    "        'discriminator': float('inf'),\n",
    "        'contrastive': float('inf')\n",
    "    }\n",
    "    patience_counters = {k: 0 for k in best_losses.keys()}\n",
    "    min_improvement = 1e-4\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_g_loss = 0\n",
    "        epoch_d_loss = 0\n",
    "        epoch_cl_loss = 0\n",
    "        epoch_struct_loss = 0\n",
    "        processed_batches = 0\n",
    "        \n",
    "        for batch_idx, batch in enumerate(dataloader):\n",
    "            batch = batch.to(device)\n",
    "            batch_size = int(batch.batch.max().item() + 1)\n",
    "            \n",
    "            # Train discriminator\n",
    "            for _ in range(critic_iterations):\n",
    "                d_optimizer.zero_grad()\n",
    "                real_scores, fake_scores, pred, h_soft = graph_gan(\n",
    "                    batch.x, batch.edge_index, batch.batch\n",
    "                )\n",
    "                \n",
    "                # Enhanced discriminator loss with structural consistency\n",
    "                d_loss = wasserstein_loss(real_scores, fake_scores)\n",
    "                struct_loss = structural_consistency_loss(batch, Data(\n",
    "                    x=h_soft,\n",
    "                    edge_index=batch.edge_index,\n",
    "                    edge_attr=batch.edge_attr,\n",
    "                    batch=batch.batch\n",
    "                ))\n",
    "                \n",
    "                total_d_loss = lambda_disc * (d_loss + 0.5 * struct_loss)\n",
    "                total_d_loss.backward(retain_graph=True)\n",
    "                \n",
    "                torch.nn.utils.clip_grad_norm_(\n",
    "                    graph_gan.discriminator.parameters(), max_norm=1.0\n",
    "                )\n",
    "                d_optimizer.step()\n",
    "            \n",
    "            # Train generator and encoder\n",
    "            g_optimizer.zero_grad()\n",
    "            e_optimizer.zero_grad()\n",
    "            \n",
    "            real_scores, fake_scores, pred, h_soft = graph_gan(\n",
    "                batch.x, batch.edge_index, batch.batch\n",
    "            )\n",
    "            \n",
    "            # Create compatible fake data\n",
    "            fake_data = Data(\n",
    "                x=h_soft,\n",
    "                edge_index=batch.edge_index,\n",
    "                edge_attr=batch.edge_attr,\n",
    "                batch=batch.batch\n",
    "            )\n",
    "            \n",
    "            # Enhanced generator loss with structural consistency\n",
    "            g_loss = -torch.mean(fake_scores)\n",
    "            struct_loss = structural_consistency_loss(batch, fake_data)\n",
    "            \n",
    "            total_g_loss = lambda_gen * (g_loss + 0.5 * struct_loss)\n",
    "            \n",
    "            # Check structural similarity with proper dimension handling\n",
    "            similarity_score = compute_structural_similarity_alternative(\n",
    "                batch.x, h_soft, batch.edge_index, batch.edge_index\n",
    "            ).item()  # Convert to scalar for comparison\n",
    "            \n",
    "            if adaptive_threshold:\n",
    "                current_threshold = similarity_threshold * (1.0 + epoch * min_similarity_increase)\n",
    "                current_threshold = min(current_threshold, 0.7)  # Cap at 0.7\n",
    "            else:\n",
    "                current_threshold = similarity_threshold\n",
    "            \n",
    "            # Only apply contrastive learning if augmentations are of sufficient quality\n",
    "            \n",
    "            if similarity_score > current_threshold:\n",
    "                real_embeddings = encoder(batch.x, batch.edge_index, batch.edge_attr, batch.batch)\n",
    "                fake_embeddings = encoder(fake_data.x, fake_data.edge_index, \n",
    "                                       fake_data.edge_attr, fake_data.batch)\n",
    "\n",
    "                cl_loss = lambda_cl * contrastive_loss(real_embeddings, fake_embeddings)\n",
    "                total_loss = total_g_loss + cl_loss\n",
    "            else:\n",
    "                # Provide gradient signal even when below threshold\n",
    "                real_embeddings = encoder(batch.x, batch.edge_index, batch.edge_attr, batch.batch)\n",
    "                fake_embeddings = encoder(fake_data.x, fake_data.edge_index, \n",
    "                                       fake_data.edge_attr, fake_data.batch)\n",
    "\n",
    "                cl_loss = lambda_cl * 0.1 * contrastive_loss(real_embeddings, fake_embeddings)\n",
    "                total_loss = total_g_loss + cl_loss\n",
    "                            \n",
    "            total_loss.backward()\n",
    "            \n",
    "            torch.nn.utils.clip_grad_norm_(graph_gan.generator.parameters(), max_norm=1.0)\n",
    "            torch.nn.utils.clip_grad_norm_(encoder.parameters(), max_norm=1.0)\n",
    "            \n",
    "            g_optimizer.step()\n",
    "            e_optimizer.step()\n",
    "            \n",
    "            # Track losses\n",
    "            epoch_g_loss += g_loss.item()\n",
    "            epoch_d_loss += d_loss.item()\n",
    "            epoch_cl_loss += cl_loss.item()\n",
    "            epoch_struct_loss += struct_loss.item()\n",
    "            processed_batches += 1\n",
    "            \n",
    "        # Calculate average losses\n",
    "        avg_g_loss = epoch_g_loss / processed_batches\n",
    "        avg_d_loss = epoch_d_loss / processed_batches\n",
    "        avg_cl_loss = epoch_cl_loss / processed_batches\n",
    "        avg_struct_loss = epoch_struct_loss / processed_batches\n",
    "        \n",
    "        # Combined loss considering both GAN and CL performance\n",
    "        combined_loss = avg_cl_loss + 0.5 * (avg_g_loss + avg_struct_loss)\n",
    "        \n",
    "        g_scheduler.step(avg_g_loss)\n",
    "        d_scheduler.step(avg_d_loss)\n",
    "        \n",
    "        # Enhanced early stopping logic\n",
    "        improved = False\n",
    "        for loss_type, loss_value in [\n",
    "            ('generator', avg_g_loss),\n",
    "            ('discriminator', avg_d_loss),\n",
    "            ('contrastive', avg_cl_loss)\n",
    "        ]:\n",
    "            if loss_value < best_losses[loss_type] - min_improvement:\n",
    "                best_losses[loss_type] = loss_value\n",
    "                patience_counters[loss_type] = 0\n",
    "                improved = True\n",
    "            else:\n",
    "                patience_counters[loss_type] += 1\n",
    "        \n",
    "        # Check if all components have stopped improving\n",
    "        if all(counter >= patience for counter in patience_counters.values()):\n",
    "            print(f\"Early stopping triggered after {epoch + 1} epochs\")\n",
    "            print(\"Component-wise patience counters:\", patience_counters)\n",
    "            break\n",
    "        \n",
    "        # Save best model if any component improved\n",
    "        if improved:\n",
    "            torch.save({\n",
    "                'graph_gan_state_dict': graph_gan.state_dict(),\n",
    "                'encoder_state_dict': encoder.state_dict(),\n",
    "                'g_optimizer_state_dict': g_optimizer.state_dict(),\n",
    "                'd_optimizer_state_dict': d_optimizer.state_dict(),\n",
    "                'e_optimizer_state_dict': e_optimizer.state_dict(),\n",
    "                'epoch': epoch,\n",
    "                'best_losses': best_losses,\n",
    "                'patience_counters': patience_counters\n",
    "            }, 'best_model_checkpoint.pt')\n",
    "        \n",
    "        # Print epoch results with learning rates\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}] - '\n",
    "              f'G_Loss: {avg_g_loss:.4f} (lr: {g_optimizer.param_groups[0][\"lr\"]:.2e}), '\n",
    "              f'D_Loss: {avg_d_loss:.4f} (lr: {d_optimizer.param_groups[0][\"lr\"]:.2e}), '\n",
    "              f'CL_Loss: {avg_cl_loss:.4f}, Struct_Loss: {avg_struct_loss:.4f}, '\n",
    "              f'Similarity: {similarity_score:.4f}')\n",
    "        \n",
    "        # Append epoch losses\n",
    "        d_losses.append(avg_d_loss / processed_batches)\n",
    "        g_losses.append(avg_g_loss / processed_batches)\n",
    "        cl_losses.append(epoch_cl_loss / processed_batches)                \n",
    "        \n",
    "    return graph_gan, encoder, d_losses, g_losses, cl_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e031be8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100] - G_Loss: -0.4969 (lr: 8.00e-06), D_Loss: -0.0256 (lr: 1.20e-05), CL_Loss: -0.4123, Struct_Loss: 0.1602, Similarity: 0.6674\n",
      "Epoch [2/100] - G_Loss: -0.4740 (lr: 8.00e-06), D_Loss: -0.0718 (lr: 1.20e-05), CL_Loss: -0.4523, Struct_Loss: 0.1602, Similarity: 0.6629\n",
      "Epoch [3/100] - G_Loss: -0.4492 (lr: 8.00e-06), D_Loss: -0.1192 (lr: 1.20e-05), CL_Loss: -0.4758, Struct_Loss: 0.1601, Similarity: 0.6187\n",
      "Epoch [4/100] - G_Loss: -0.4217 (lr: 8.00e-06), D_Loss: -0.1771 (lr: 1.20e-05), CL_Loss: -0.4933, Struct_Loss: 0.1601, Similarity: 0.7016\n",
      "Epoch [5/100] - G_Loss: -0.3956 (lr: 8.00e-06), D_Loss: -0.2435 (lr: 1.20e-05), CL_Loss: -0.4993, Struct_Loss: 0.1600, Similarity: 0.6842\n",
      "Epoch [6/100] - G_Loss: -0.3603 (lr: 8.00e-06), D_Loss: -0.3185 (lr: 1.20e-05), CL_Loss: -0.5072, Struct_Loss: 0.1602, Similarity: 0.6747\n",
      "Epoch 00007: reducing learning rate of group 0 to 4.0000e-06.\n",
      "Epoch [7/100] - G_Loss: -0.3232 (lr: 4.00e-06), D_Loss: -0.3933 (lr: 1.20e-05), CL_Loss: -0.5101, Struct_Loss: 0.1601, Similarity: 0.7332\n",
      "Epoch [8/100] - G_Loss: -0.2873 (lr: 4.00e-06), D_Loss: -0.4648 (lr: 1.20e-05), CL_Loss: -0.5185, Struct_Loss: 0.1599, Similarity: 0.6593\n",
      "Epoch [9/100] - G_Loss: -0.2510 (lr: 4.00e-06), D_Loss: -0.5317 (lr: 1.20e-05), CL_Loss: -0.5242, Struct_Loss: 0.1602, Similarity: 0.7110\n",
      "Epoch [10/100] - G_Loss: -0.2221 (lr: 4.00e-06), D_Loss: -0.5878 (lr: 1.20e-05), CL_Loss: -0.5230, Struct_Loss: 0.1599, Similarity: 0.7385\n",
      "Epoch [11/100] - G_Loss: -0.1954 (lr: 4.00e-06), D_Loss: -0.6346 (lr: 1.20e-05), CL_Loss: -0.5236, Struct_Loss: 0.1601, Similarity: 0.7400\n",
      "Epoch [12/100] - G_Loss: -0.1713 (lr: 4.00e-06), D_Loss: -0.6756 (lr: 1.20e-05), CL_Loss: -0.5283, Struct_Loss: 0.1600, Similarity: 0.6936\n",
      "Epoch 00013: reducing learning rate of group 0 to 2.0000e-06.\n",
      "Epoch [13/100] - G_Loss: -0.1526 (lr: 2.00e-06), D_Loss: -0.7095 (lr: 1.20e-05), CL_Loss: -0.5301, Struct_Loss: 0.1603, Similarity: 0.7010\n",
      "Epoch [14/100] - G_Loss: -0.1355 (lr: 2.00e-06), D_Loss: -0.7393 (lr: 1.20e-05), CL_Loss: -0.5314, Struct_Loss: 0.1604, Similarity: 0.6881\n",
      "Epoch [15/100] - G_Loss: -0.1219 (lr: 2.00e-06), D_Loss: -0.7652 (lr: 1.20e-05), CL_Loss: -0.5347, Struct_Loss: 0.1600, Similarity: 0.6870\n",
      "Epoch [16/100] - G_Loss: -0.1093 (lr: 2.00e-06), D_Loss: -0.7884 (lr: 1.20e-05), CL_Loss: -0.5363, Struct_Loss: 0.1599, Similarity: 0.6834\n",
      "Epoch [17/100] - G_Loss: -0.0979 (lr: 2.00e-06), D_Loss: -0.8093 (lr: 1.20e-05), CL_Loss: -0.5384, Struct_Loss: 0.1603, Similarity: 0.7148\n",
      "Epoch [18/100] - G_Loss: -0.0884 (lr: 2.00e-06), D_Loss: -0.8256 (lr: 1.20e-05), CL_Loss: -0.5410, Struct_Loss: 0.1601, Similarity: 0.6857\n",
      "Epoch 00019: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch [19/100] - G_Loss: -0.0796 (lr: 1.00e-06), D_Loss: -0.8406 (lr: 1.20e-05), CL_Loss: -0.5398, Struct_Loss: 0.1601, Similarity: 0.6741\n",
      "Epoch [20/100] - G_Loss: -0.0731 (lr: 1.00e-06), D_Loss: -0.8544 (lr: 1.20e-05), CL_Loss: -0.5418, Struct_Loss: 0.1601, Similarity: 0.6745\n",
      "Epoch [21/100] - G_Loss: -0.0657 (lr: 1.00e-06), D_Loss: -0.8663 (lr: 1.20e-05), CL_Loss: -0.5451, Struct_Loss: 0.1602, Similarity: 0.6623\n",
      "Epoch [22/100] - G_Loss: -0.0604 (lr: 1.00e-06), D_Loss: -0.8775 (lr: 1.20e-05), CL_Loss: -0.5439, Struct_Loss: 0.1600, Similarity: 0.6874\n",
      "Epoch [23/100] - G_Loss: -0.0553 (lr: 1.00e-06), D_Loss: -0.8864 (lr: 1.20e-05), CL_Loss: -0.5454, Struct_Loss: 0.1602, Similarity: 0.7109\n",
      "Epoch [24/100] - G_Loss: -0.0511 (lr: 1.00e-06), D_Loss: -0.8957 (lr: 1.20e-05), CL_Loss: -0.5468, Struct_Loss: 0.1600, Similarity: 0.6795\n",
      "Epoch 00025: reducing learning rate of group 0 to 5.0000e-07.\n",
      "Epoch [25/100] - G_Loss: -0.0473 (lr: 5.00e-07), D_Loss: -0.9034 (lr: 1.20e-05), CL_Loss: -0.5470, Struct_Loss: 0.1600, Similarity: 0.6892\n",
      "Epoch [26/100] - G_Loss: -0.0432 (lr: 5.00e-07), D_Loss: -0.9106 (lr: 1.20e-05), CL_Loss: -0.5489, Struct_Loss: 0.1601, Similarity: 0.7218\n",
      "Epoch [27/100] - G_Loss: -0.0403 (lr: 5.00e-07), D_Loss: -0.9169 (lr: 1.20e-05), CL_Loss: -0.5481, Struct_Loss: 0.1601, Similarity: 0.6581\n",
      "Epoch [28/100] - G_Loss: -0.0369 (lr: 5.00e-07), D_Loss: -0.9233 (lr: 1.20e-05), CL_Loss: -0.5514, Struct_Loss: 0.1603, Similarity: 0.6786\n",
      "Epoch [29/100] - G_Loss: -0.0342 (lr: 5.00e-07), D_Loss: -0.9282 (lr: 1.20e-05), CL_Loss: -0.5510, Struct_Loss: 0.1600, Similarity: 0.7279\n",
      "Epoch [30/100] - G_Loss: -0.0320 (lr: 5.00e-07), D_Loss: -0.9336 (lr: 1.20e-05), CL_Loss: -0.5524, Struct_Loss: 0.1599, Similarity: 0.7263\n",
      "Epoch 00031: reducing learning rate of group 0 to 2.5000e-07.\n",
      "Epoch [31/100] - G_Loss: -0.0296 (lr: 2.50e-07), D_Loss: -0.9377 (lr: 1.20e-05), CL_Loss: -0.5540, Struct_Loss: 0.1601, Similarity: 0.7038\n",
      "Epoch [32/100] - G_Loss: -0.0274 (lr: 2.50e-07), D_Loss: -0.9422 (lr: 1.20e-05), CL_Loss: -0.5508, Struct_Loss: 0.1601, Similarity: 0.7169\n",
      "Epoch [33/100] - G_Loss: -0.0255 (lr: 2.50e-07), D_Loss: -0.9456 (lr: 1.20e-05), CL_Loss: -0.5539, Struct_Loss: 0.1601, Similarity: 0.6950\n",
      "Epoch [34/100] - G_Loss: -0.0241 (lr: 2.50e-07), D_Loss: -0.9489 (lr: 1.20e-05), CL_Loss: -0.5547, Struct_Loss: 0.1599, Similarity: 0.7078\n",
      "Epoch [35/100] - G_Loss: -0.0226 (lr: 2.50e-07), D_Loss: -0.9522 (lr: 1.20e-05), CL_Loss: -0.5547, Struct_Loss: 0.1601, Similarity: 0.6619\n",
      "Epoch [36/100] - G_Loss: -0.0212 (lr: 2.50e-07), D_Loss: -0.9548 (lr: 1.20e-05), CL_Loss: -0.5552, Struct_Loss: 0.1602, Similarity: 0.7231\n",
      "Epoch 00037: reducing learning rate of group 0 to 1.2500e-07.\n",
      "Epoch [37/100] - G_Loss: -0.0198 (lr: 1.25e-07), D_Loss: -0.9576 (lr: 1.20e-05), CL_Loss: -0.5564, Struct_Loss: 0.1601, Similarity: 0.6533\n",
      "Epoch [38/100] - G_Loss: -0.0187 (lr: 1.25e-07), D_Loss: -0.9601 (lr: 1.20e-05), CL_Loss: -0.5569, Struct_Loss: 0.1601, Similarity: 0.7047\n",
      "Epoch [39/100] - G_Loss: -0.0176 (lr: 1.25e-07), D_Loss: -0.9625 (lr: 1.20e-05), CL_Loss: -0.5579, Struct_Loss: 0.1602, Similarity: 0.6833\n",
      "Epoch [40/100] - G_Loss: -0.0167 (lr: 1.25e-07), D_Loss: -0.9643 (lr: 1.20e-05), CL_Loss: -0.5579, Struct_Loss: 0.1601, Similarity: 0.6865\n",
      "Epoch [41/100] - G_Loss: -0.0157 (lr: 1.25e-07), D_Loss: -0.9663 (lr: 1.20e-05), CL_Loss: -0.5587, Struct_Loss: 0.1600, Similarity: 0.7167\n",
      "Epoch [42/100] - G_Loss: -0.0150 (lr: 1.25e-07), D_Loss: -0.9679 (lr: 1.20e-05), CL_Loss: -0.5604, Struct_Loss: 0.1601, Similarity: 0.6634\n",
      "Epoch 00043: reducing learning rate of group 0 to 6.2500e-08.\n",
      "Epoch [43/100] - G_Loss: -0.0141 (lr: 6.25e-08), D_Loss: -0.9695 (lr: 1.20e-05), CL_Loss: -0.5593, Struct_Loss: 0.1601, Similarity: 0.6616\n",
      "Epoch [44/100] - G_Loss: -0.0134 (lr: 6.25e-08), D_Loss: -0.9712 (lr: 1.20e-05), CL_Loss: -0.5590, Struct_Loss: 0.1600, Similarity: 0.7203\n",
      "Epoch [45/100] - G_Loss: -0.0126 (lr: 6.25e-08), D_Loss: -0.9726 (lr: 1.20e-05), CL_Loss: -0.5616, Struct_Loss: 0.1603, Similarity: 0.6747\n",
      "Epoch [46/100] - G_Loss: -0.0120 (lr: 6.25e-08), D_Loss: -0.9741 (lr: 1.20e-05), CL_Loss: -0.5611, Struct_Loss: 0.1602, Similarity: 0.6918\n",
      "Epoch [47/100] - G_Loss: -0.0114 (lr: 6.25e-08), D_Loss: -0.9753 (lr: 1.20e-05), CL_Loss: -0.5615, Struct_Loss: 0.1603, Similarity: 0.6998\n",
      "Epoch [48/100] - G_Loss: -0.0109 (lr: 6.25e-08), D_Loss: -0.9766 (lr: 1.20e-05), CL_Loss: -0.5613, Struct_Loss: 0.1603, Similarity: 0.7050\n",
      "Epoch 00049: reducing learning rate of group 0 to 3.1250e-08.\n",
      "Epoch [49/100] - G_Loss: -0.0104 (lr: 3.13e-08), D_Loss: -0.9776 (lr: 1.20e-05), CL_Loss: -0.5633, Struct_Loss: 0.1599, Similarity: 0.6557\n",
      "Epoch [50/100] - G_Loss: -0.0098 (lr: 3.13e-08), D_Loss: -0.9788 (lr: 1.20e-05), CL_Loss: -0.5622, Struct_Loss: 0.1602, Similarity: 0.7588\n",
      "Epoch [51/100] - G_Loss: -0.0094 (lr: 3.13e-08), D_Loss: -0.9797 (lr: 1.20e-05), CL_Loss: -0.5636, Struct_Loss: 0.1602, Similarity: 0.7178\n",
      "Epoch [52/100] - G_Loss: -0.0089 (lr: 3.13e-08), D_Loss: -0.9806 (lr: 1.20e-05), CL_Loss: -0.5620, Struct_Loss: 0.1600, Similarity: 0.6717\n",
      "Epoch [53/100] - G_Loss: -0.0087 (lr: 3.13e-08), D_Loss: -0.9815 (lr: 1.20e-05), CL_Loss: -0.5620, Struct_Loss: 0.1599, Similarity: 0.7129\n",
      "Epoch [54/100] - G_Loss: -0.0082 (lr: 3.13e-08), D_Loss: -0.9824 (lr: 1.20e-05), CL_Loss: -0.5645, Struct_Loss: 0.1602, Similarity: 0.7705\n",
      "Epoch 00055: reducing learning rate of group 0 to 1.5625e-08.\n",
      "Epoch [55/100] - G_Loss: -0.0078 (lr: 1.56e-08), D_Loss: -0.9832 (lr: 1.20e-05), CL_Loss: -0.5647, Struct_Loss: 0.1601, Similarity: 0.7112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [56/100] - G_Loss: -0.0074 (lr: 1.56e-08), D_Loss: -0.9839 (lr: 1.20e-05), CL_Loss: -0.5652, Struct_Loss: 0.1603, Similarity: 0.6709\n",
      "Epoch [57/100] - G_Loss: -0.0071 (lr: 1.56e-08), D_Loss: -0.9846 (lr: 1.20e-05), CL_Loss: -0.5657, Struct_Loss: 0.1598, Similarity: 0.6947\n",
      "Epoch [58/100] - G_Loss: -0.0068 (lr: 1.56e-08), D_Loss: -0.9853 (lr: 1.20e-05), CL_Loss: -0.5661, Struct_Loss: 0.1600, Similarity: 0.7042\n",
      "Epoch [59/100] - G_Loss: -0.0064 (lr: 1.56e-08), D_Loss: -0.9858 (lr: 1.20e-05), CL_Loss: -0.5652, Struct_Loss: 0.1602, Similarity: 0.6389\n",
      "Epoch [60/100] - G_Loss: -0.0062 (lr: 1.56e-08), D_Loss: -0.9865 (lr: 1.20e-05), CL_Loss: -0.5653, Struct_Loss: 0.1601, Similarity: 0.6852\n",
      "Epoch [61/100] - G_Loss: -0.0059 (lr: 1.56e-08), D_Loss: -0.9871 (lr: 1.20e-05), CL_Loss: -0.5672, Struct_Loss: 0.1602, Similarity: 0.6440\n",
      "Epoch [62/100] - G_Loss: -0.0057 (lr: 1.56e-08), D_Loss: -0.9876 (lr: 1.20e-05), CL_Loss: -0.5660, Struct_Loss: 0.1601, Similarity: 0.7157\n",
      "Epoch [63/100] - G_Loss: -0.0055 (lr: 1.56e-08), D_Loss: -0.9882 (lr: 1.20e-05), CL_Loss: -0.5679, Struct_Loss: 0.1599, Similarity: 0.7372\n",
      "Epoch [64/100] - G_Loss: -0.0052 (lr: 1.56e-08), D_Loss: -0.9887 (lr: 1.20e-05), CL_Loss: -0.5688, Struct_Loss: 0.1601, Similarity: 0.7600\n",
      "Epoch [65/100] - G_Loss: -0.0050 (lr: 1.56e-08), D_Loss: -0.9891 (lr: 1.20e-05), CL_Loss: -0.5686, Struct_Loss: 0.1603, Similarity: 0.6715\n",
      "Epoch [66/100] - G_Loss: -0.0048 (lr: 1.56e-08), D_Loss: -0.9896 (lr: 1.20e-05), CL_Loss: -0.5682, Struct_Loss: 0.1600, Similarity: 0.6642\n",
      "Epoch [67/100] - G_Loss: -0.0047 (lr: 1.56e-08), D_Loss: -0.9900 (lr: 1.20e-05), CL_Loss: -0.5675, Struct_Loss: 0.1602, Similarity: 0.7435\n",
      "Epoch [68/100] - G_Loss: -0.0045 (lr: 1.56e-08), D_Loss: -0.9903 (lr: 1.20e-05), CL_Loss: -0.5687, Struct_Loss: 0.1601, Similarity: 0.6849\n",
      "Epoch [69/100] - G_Loss: -0.0043 (lr: 1.56e-08), D_Loss: -0.9907 (lr: 1.20e-05), CL_Loss: -0.5712, Struct_Loss: 0.1600, Similarity: 0.7445\n",
      "Epoch [70/100] - G_Loss: -0.0041 (lr: 1.56e-08), D_Loss: -0.9911 (lr: 1.20e-05), CL_Loss: -0.5709, Struct_Loss: 0.1602, Similarity: 0.6839\n",
      "Epoch [71/100] - G_Loss: -0.0039 (lr: 1.56e-08), D_Loss: -0.9915 (lr: 1.20e-05), CL_Loss: -0.5714, Struct_Loss: 0.1605, Similarity: 0.7519\n",
      "Epoch [72/100] - G_Loss: -0.0038 (lr: 1.56e-08), D_Loss: -0.9917 (lr: 1.20e-05), CL_Loss: -0.5725, Struct_Loss: 0.1603, Similarity: 0.6834\n",
      "Epoch [73/100] - G_Loss: -0.0036 (lr: 1.56e-08), D_Loss: -0.9921 (lr: 1.20e-05), CL_Loss: -0.5708, Struct_Loss: 0.1600, Similarity: 0.7545\n",
      "Epoch [74/100] - G_Loss: -0.0035 (lr: 1.56e-08), D_Loss: -0.9923 (lr: 1.20e-05), CL_Loss: -0.5701, Struct_Loss: 0.1602, Similarity: 0.6896\n",
      "Epoch [75/100] - G_Loss: -0.0034 (lr: 1.56e-08), D_Loss: -0.9927 (lr: 1.20e-05), CL_Loss: -0.5726, Struct_Loss: 0.1601, Similarity: 0.7403\n",
      "Epoch [76/100] - G_Loss: -0.0033 (lr: 1.56e-08), D_Loss: -0.9930 (lr: 1.20e-05), CL_Loss: -0.5721, Struct_Loss: 0.1598, Similarity: 0.6931\n",
      "Epoch [77/100] - G_Loss: -0.0031 (lr: 1.56e-08), D_Loss: -0.9932 (lr: 1.20e-05), CL_Loss: -0.5732, Struct_Loss: 0.1599, Similarity: 0.7204\n",
      "Epoch [78/100] - G_Loss: -0.0030 (lr: 1.56e-08), D_Loss: -0.9935 (lr: 1.20e-05), CL_Loss: -0.5732, Struct_Loss: 0.1599, Similarity: 0.6985\n",
      "Epoch [79/100] - G_Loss: -0.0029 (lr: 1.56e-08), D_Loss: -0.9937 (lr: 1.20e-05), CL_Loss: -0.5732, Struct_Loss: 0.1602, Similarity: 0.7538\n",
      "Epoch [80/100] - G_Loss: -0.0028 (lr: 1.56e-08), D_Loss: -0.9939 (lr: 1.20e-05), CL_Loss: -0.5738, Struct_Loss: 0.1601, Similarity: 0.7340\n",
      "Epoch [81/100] - G_Loss: -0.0027 (lr: 1.56e-08), D_Loss: -0.9942 (lr: 1.20e-05), CL_Loss: -0.5736, Struct_Loss: 0.1599, Similarity: 0.7224\n",
      "Epoch [82/100] - G_Loss: -0.0026 (lr: 1.56e-08), D_Loss: -0.9944 (lr: 1.20e-05), CL_Loss: -0.5731, Struct_Loss: 0.1602, Similarity: 0.7467\n",
      "Epoch [83/100] - G_Loss: -0.0025 (lr: 1.56e-08), D_Loss: -0.9946 (lr: 1.20e-05), CL_Loss: -0.5735, Struct_Loss: 0.1601, Similarity: 0.7093\n",
      "Epoch [84/100] - G_Loss: -0.0024 (lr: 1.56e-08), D_Loss: -0.9947 (lr: 1.20e-05), CL_Loss: -0.5756, Struct_Loss: 0.1602, Similarity: 0.7110\n",
      "Epoch [85/100] - G_Loss: -0.0023 (lr: 1.56e-08), D_Loss: -0.9950 (lr: 1.20e-05), CL_Loss: -0.5752, Struct_Loss: 0.1600, Similarity: 0.7189\n",
      "Epoch [86/100] - G_Loss: -0.0022 (lr: 1.56e-08), D_Loss: -0.9952 (lr: 1.20e-05), CL_Loss: -0.5768, Struct_Loss: 0.1602, Similarity: 0.7237\n",
      "Epoch [87/100] - G_Loss: -0.0021 (lr: 1.56e-08), D_Loss: -0.9953 (lr: 1.20e-05), CL_Loss: -0.5769, Struct_Loss: 0.1601, Similarity: 0.6577\n",
      "Epoch [88/100] - G_Loss: -0.0021 (lr: 1.56e-08), D_Loss: -0.9955 (lr: 1.20e-05), CL_Loss: -0.5759, Struct_Loss: 0.1601, Similarity: 0.7510\n",
      "Epoch [89/100] - G_Loss: -0.0020 (lr: 1.56e-08), D_Loss: -0.9956 (lr: 1.20e-05), CL_Loss: -0.5768, Struct_Loss: 0.1602, Similarity: 0.6908\n",
      "Epoch [90/100] - G_Loss: -0.0019 (lr: 1.56e-08), D_Loss: -0.9958 (lr: 1.20e-05), CL_Loss: -0.5769, Struct_Loss: 0.1601, Similarity: 0.6889\n",
      "Epoch [91/100] - G_Loss: -0.0019 (lr: 1.56e-08), D_Loss: -0.9960 (lr: 1.20e-05), CL_Loss: -0.5790, Struct_Loss: 0.1600, Similarity: 0.6677\n",
      "Epoch [92/100] - G_Loss: -0.0018 (lr: 1.56e-08), D_Loss: -0.9961 (lr: 1.20e-05), CL_Loss: -0.5783, Struct_Loss: 0.1602, Similarity: 0.7073\n",
      "Epoch [93/100] - G_Loss: -0.0017 (lr: 1.56e-08), D_Loss: -0.9962 (lr: 1.20e-05), CL_Loss: -0.5777, Struct_Loss: 0.1602, Similarity: 0.6713\n",
      "Epoch [94/100] - G_Loss: -0.0017 (lr: 1.56e-08), D_Loss: -0.9963 (lr: 1.20e-05), CL_Loss: -0.5802, Struct_Loss: 0.1602, Similarity: 0.6571\n",
      "Epoch [95/100] - G_Loss: -0.0016 (lr: 1.56e-08), D_Loss: -0.9964 (lr: 1.20e-05), CL_Loss: -0.5806, Struct_Loss: 0.1603, Similarity: 0.7174\n",
      "Epoch [96/100] - G_Loss: -0.0015 (lr: 1.56e-08), D_Loss: -0.9966 (lr: 1.20e-05), CL_Loss: -0.5811, Struct_Loss: 0.1602, Similarity: 0.6796\n",
      "Epoch [97/100] - G_Loss: -0.0015 (lr: 1.56e-08), D_Loss: -0.9967 (lr: 1.20e-05), CL_Loss: -0.5802, Struct_Loss: 0.1602, Similarity: 0.6783\n",
      "Epoch [98/100] - G_Loss: -0.0015 (lr: 1.56e-08), D_Loss: -0.9968 (lr: 1.20e-05), CL_Loss: -0.5817, Struct_Loss: 0.1602, Similarity: 0.6719\n",
      "Epoch [99/100] - G_Loss: -0.0014 (lr: 1.56e-08), D_Loss: -0.9969 (lr: 1.20e-05), CL_Loss: -0.5833, Struct_Loss: 0.1603, Similarity: 0.6980\n",
      "Epoch [100/100] - G_Loss: -0.0013 (lr: 1.56e-08), D_Loss: -0.9970 (lr: 1.20e-05), CL_Loss: -0.5842, Struct_Loss: 0.1602, Similarity: 0.7293\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_losses(d_losses, g_losses, cl_losses):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(d_losses, label='Discriminator Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(g_losses, label='Generator Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.plot(cl_losses, label='Contrastive Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    # Read data\n",
    "    smiles_df = pd.read_csv(\"D:\\\\PhD\\\\Chapter3\\\\Unsupervised_GAN_Code\\\\pubchem-10m-clean_test.txt\", \n",
    "                           header=None, names=['SMILES'])\n",
    "    num_epochs=100\n",
    "    \n",
    "    # Train models with error handling\n",
    "#     try:\n",
    "    graph_gan, encoder, d_losses, g_losses, cl_losses = train_gan_cl_improved(smiles_df, num_epochs)\n",
    "\n",
    "    # Plot losses\n",
    "    plot_losses(d_losses, g_losses, cl_losses)\n",
    "\n",
    "    # Save models\n",
    "    torch.save({\n",
    "        'graph_gan_state_dict': graph_gan.state_dict(),\n",
    "        'encoder_state_dict': encoder.state_dict()\n",
    "    }, 'molecular_gan_cl_models_CA11.pt')\n",
    "        \n",
    "#     except Exception as e:\n",
    "#         print(f\"Training failed: {str(e)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (MyEnv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
